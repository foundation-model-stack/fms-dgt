name: star_transform
blocks:
  - name: llm1
    type: vllm-server
    decoding_method: sample
    temperature: 0.5
    max_new_tokens: 1024
    min_new_tokens: 1
    # model_id_or_path: /dccstor/cfm-tst/fms-sdg/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1/snapshots/2dcff66eac0c01dc50e4c41eea959968232187fe
    model_id_or_path: /dccstor/cfm-tst/fms-sdg/.cache/huggingface/hub/models--ibm-granite--granite-8b-code-instruct/snapshots/c4d3fcd4a373406a803105099fb32f8be9b5e36c/
    stop_sequences:
      - "Input:"
    arg_fields:
      - prompt
    kwarg_fields:
      - stop_sequences
    result_field: result
  - name: trainer1
    type: fms-hf-tuning
    config_path: /dccstor/cfm-tst/fms-sdg/fms_dgt/databuilders/transformation/star/trainer_configs/ds_config.json
    # training args
    learning_rate: 0.0001
    fp16: true
    logging_steps: 100
    save_steps: 50
    per_device_train_batch_size: 1
    gradient_accumulation_steps: 1
    max_steps: 100
metadata:
  version: 1.0
