# Standard
from dataclasses import asdict, dataclass
from typing import Any, Dict, Iterable, List, Mapping, Optional, Union

# Local
from fms_dgt.base.databuilder import DataBuilderConfig, TransformationDataBuilder
from fms_dgt.base.registry import register_data_builder
from fms_dgt.blocks.compositions.sequence import BlockSequence, validate_block_sequence
from fms_dgt.constants import DATASET_TYPE, NAME_KEY
from fms_dgt.databuilders.nonstandard.pipeline.task import PipelineTransformTask
from fms_dgt.utils import init_dataclass_from_dict, sdg_logger


@dataclass(kw_only=True)
class PipelineDataBuilderConfig(DataBuilderConfig):
    """Configuration for a data builder.

    Attributes:
        name (Optional[str]): The name of the data builder.
        blocks (Optional[List[Dict]]): A list of block configurations.
        block_sequence (Optional[List[Dict]]): The sequence of blocks to call.
        metadata (Optional[Dict[str, Any]]): Metadata for the data builder. Allows for users to pass arbitrary info to data builders.
    """

    block_sequence: List[Dict]

    def __post_init__(self) -> None:
        super().__post_init__()
        validate_block_sequence(self.block_sequence)


@register_data_builder("transform_pipeline")
class PipelineTransformation(TransformationDataBuilder):
    """A pipeline is a config-based approach for constructing data for a set of tasks"""

    TASK_TYPE = PipelineTransformTask

    def __init__(
        self,
        config: Union[Mapping, PipelineDataBuilderConfig] = None,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        config = init_dataclass_from_dict(config, PipelineDataBuilderConfig)
        super().__init__(config=config, *args, **kwargs)

    def _init_blocks(self):
        self._pipeline = BlockSequence(**asdict(self.config))
        self._blocks = self._pipeline.blocks

    def call_with_task_list(self, tasks: List[PipelineTransformTask]) -> Iterable[Dict]:
        """Executes data builder __call__ function for all in-progress tasks.

        Args:
            tasks (List[SdgTask]): List of in-progress tasks

        Returns:
            Iterable[SdgData]: List of data instances generated by the __call__ function
        """
        for task in tasks:
            sdg_logger.info("Running task: %s", task.name)
            data_pool = task.get_batch_examples()
            while data_pool:
                args = [data_pool]
                kwargs = dict()
                for output in self(*args, **kwargs):
                    output["task_name"] = task.name
                    yield output
                data_pool = task.get_batch_examples()

    def __call__(self, data_pool: DATASET_TYPE):
        return self._pipeline(data_pool)
